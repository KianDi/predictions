{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Generate Observations using LangChain Templates\n",
    "\n",
    "- **Goal:** Prediction Similarity\n",
    "\n",
    "- **Purpose:** To implement step 1 with sub steps of prediction similarity pipeline. See steps\n",
    "    1. Generate predictions\n",
    "        1. Create several prediction prompts templates\n",
    "        2. Utilize open-source LLMs to generate predictions\n",
    "    2. Generate observations    \n",
    "\n",
    "- **Misc:**\n",
    "    - `%store`: Cell magic will store the variable of interest so we can load in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PipelinePromptTemplate, PromptTemplate\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from log_files import LogData\n",
    "from data_processing import DataProcessing\n",
    "from text_generation_models import TextGenerationModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "print(tgmf)\n",
    "llama_versatile_generation_model = tgmf.create_instance(model_name='llama-3.3-70b-versatile')\n",
    "llama_instant_generation_model = tgmf.create_instance('llama-3.1-8b-instant')\n",
    "llama_70b_8192_generation_model = tgmf.create_instance('llama3-70b-8192')\n",
    "llama_8b_8192_generation_model = tgmf.create_instance('llama3-8b-8192')\n",
    "\n",
    "gpt_35_turbo_generation_model = tgmf.create_instance('gpt-3.5-turbo')\n",
    "gpt_4_o_generation_model = tgmf.create_instance('gpt-4o')\n",
    "mixtral_87b_instruct_generation_model = tgmf.create_instance('mixtral-8x7b-instruct') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Templates for Any Domain Non-Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_template = \"\"\"{observation_properties}\n",
    "\n",
    "{observation_requirements}\n",
    "\"\"\"\n",
    "observation_prompt = PromptTemplate.from_template(observation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_properties_template = \"\"\"An observation <o> = (<o_s>, <p_t>, <o_d>, <o_a>), where it consists of the following four properties:\n",
    "\n",
    "    1. <o_s>, any source entity in the {observation_domain} domain.\n",
    "        - Can be a person (with a name) or a {observation_domain} person such as a {observation_domain} reporter, {observation_domain} analyst, {observation_domain} expert, {observation_domain} top executive, {observation_domain} senior level person, etc), civilian.\n",
    "        - Can only be an organization that is associated with the {observation_domain} obervation.\n",
    "    2. <o_t>, any target entity in the {observation_domain} domain.\n",
    "\t    - Can be a person (with a name) or a {observation_domain} person such as a {observation_domain} reporter, {observation_domain} analyst, {observation_domain} expert, {observation_domain} top executive, {observation_domain} senior level person, etc).\n",
    "        - Can only be an organization that is associated with the {observation_domain} obervation.\n",
    "    3. <o_d>, date or time range when <p> is expected to come to fruition or when one should observe the <p>.\n",
    "        - Forecast can range from a second to anytime in the future.\n",
    "        - Answers the questions: \"How far to go out from today?\" or \"Where to stop?\".\n",
    "    4. <o_a>, {observation_domain} obervation attribute.\n",
    "        - Characteristics of a domain-specific attributes such as various quantifiable metrics relevant to the {observation_domain} domain.\n",
    "        - Some examples are {observation_attributes}.\n",
    "\"\"\"\n",
    "observation_properties_prompt = PromptTemplate.from_template(observation_properties_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_requirements = \"\"\" requirements to use for each observation:\n",
    "\n",
    "    - Should be based on real-world {observation_domain} data and not hallucinate.\n",
    "    - Must be a simple sentence (observation) (and NOT compounding using \"and\" or \"or\").\n",
    "    - Should diversify all four properties of the observation (<o>) as in change and not use same for <p_s>, <p_t>, <p_d>, <p_a>.\n",
    "    - The observation should be unique and not repeated.\n",
    "    - Do not number the observations.\n",
    "    - Do not say, \"Here are {observation_N} unique observation based on the provided templates and examples:\" or anything similar in the prompt.\n",
    "    - Change how the current date (<p_d>) written in the observation with examples of (1) Wednesday, August 21, 2024; (2) Wed, August 21, 2024; (3) 08/21/2024; (4) 08/21/2024; (5) 21/08/2024; (6) 21 August 2024; (7) 2024/08/21; (8) 2024-08-21; (9) August 21, 2024; (10) Aug 21, 2024; (11) 21 August 2024, (12) 21 Aug 2024, Q3 of 2027, 2029 of Q3, etc (with removing day of week).\n",
    "    - Do not use any of the examples in the prompt.\n",
    "    - In front of every observation, put the template number in the format of \"T0:\" and only use \"T0:\" as the template number.\n",
    "    - Do not put template number on line by itself. Always pair with an observation.\n",
    "    - Disregard brackets: \"<>\"\n",
    "    - Do not use person name of entity name more than once as in don't use name Joe as both the <p_s> and <p_t>, unless like Mr. Sach and Goldman Sach or Mr. Sam Walton and Sam's Club, etc.\n",
    "    - The source entity (<p_s>) is rarely the same as the target entity (<p_t>) and if same, the <p_s> is making a observation on itself in the <p_t>.\n",
    "    - Should variate the slope of rise/increase/as much as, fall/decrease/as little as, change, stay stable, high/low chance/probability/degree of, etc.\n",
    "    - Should variate the observation verbs such as will, would, be going to, should, etc.\n",
    "    - Must be past tense as in already occurred and not future tense.\"\"\"\n",
    "observation_requirements_prompt = PromptTemplate.from_template(observation_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_input_prompts = [\n",
    "    (\"observation_properties\", observation_properties_prompt),\n",
    "    (\"observation_requirements\", observation_requirements_prompt),\n",
    "]\n",
    "\n",
    "observation_pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=observation_prompt, pipeline_prompts=observation_input_prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_N = 1\n",
    "\n",
    "financial_attributes = \"\"\"stock price, net profit, revenue, operating cash flow, research and development expenses, operating income, gross profit.\"\"\"\n",
    "health_attributes = \"\"\"obesity rates, prevalence of chronic illnesses, average physical activity levels, nutritional intake, etc.\"\"\"\n",
    "policy_attributes = \"\"\"election outcomes, economic reforms, legislative impacts.\"\"\"\n",
    "weather_attributes = \"\"\"temperature, precipitation, wind speed, humidity, etc.\"\"\"\n",
    "\n",
    "observation_attributes = f\"{financial_attributes} + {health_attributes} + {policy_attributes} + {weather_attributes}\"\n",
    "\n",
    "observation_input_dict = {\n",
    "    \"observation_domain\": \"finance, health, policy, weather, sports\",\n",
    "    \"observation_attributes\": observation_attributes,\n",
    "    \"observation_N\": observation_N\n",
    "}\n",
    "\n",
    "observation_prompt_output = observation_pipeline_prompt.format(**observation_input_dict)\n",
    "print(observation_prompt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Generation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "N_batches = 1\n",
    "\n",
    "# text_generation_models = [llama_versatile_generation_model, llama_instant_generation_model, llama_70b_8192_generation_model, \n",
    "#                           llama_8b_8192_generation_model, gpt_35_turbo_generation_model, gpt_4_o_generation_model, \n",
    "#                           mixtral_87b_instruct_generation_model]\n",
    "\n",
    "text_generation_models = [gpt_4_o_generation_model, \n",
    "                          mixtral_87b_instruct_generation_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_domains = [\"mixed\"]\n",
    "observation_prompt_outputs = {\n",
    "    \"mixed\": observation_prompt_output,\n",
    "}\n",
    "non_prediction_label = 0\n",
    "\n",
    "batched_non_predictions_df = tgmf.batch_generate_predictions(N_batches=N_batches,\n",
    "                                text_generation_models=text_generation_models,\n",
    "                                domains=observation_prompt_outputs,\n",
    "                                prompt_outputs=observation_prompt_outputs,\n",
    "                                sentence_label=non_prediction_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "batched_non_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_predictions_df = DataProcessing.concat_dfs(batched_non_predictions_df)\n",
    "non_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
