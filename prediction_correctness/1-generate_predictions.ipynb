{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc9e2f4",
   "metadata": {},
   "source": [
    "# 1-Generate Predictions using LangChain\n",
    "\n",
    "- **Goal:** Prediction Recognition\n",
    "\n",
    "- **Purpose:** To implement step 1 with sub steps of prediction recognition pipeline. See steps\n",
    "    1. Generate predictions\n",
    "        1. Create several prediction prompts templates\n",
    "        2. Utilize open-source LLMs to generate predictions\n",
    "\n",
    "- **Misc:**\n",
    "    - `%store`: Cell magic will store the variable of interest so we can load in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas langchain spacy numpy Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn pandas tqdm langchain-core spacy groq python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.join(notebook_dir, '../'))\n",
    "\n",
    "from log_files import DataFrameLogger\n",
    "from data_processing import DataProcessing\n",
    "from text_generation_models import TextGenerationModelFactory, LlamaVersatileTextGenerationModel, LlamaInstantTextGenerationModel, Llama70B8192TextGenerationModel, Llama8B8192TextGenerationModel, MixtralTextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f573fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_colwidth', 800)\n",
    "\n",
    "llama_versatile_generation_model = LlamaVersatileTextGenerationModel()\n",
    "llama_instant_generation_model = LlamaInstantTextGenerationModel()\n",
    "llama_70b_8192_generation_model = Llama70B8192TextGenerationModel()\n",
    "llama_8b_8192_generation_model = Llama8B8192TextGenerationModel()\n",
    "mixtral_generation_model = MixtralTextGenerationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f78c6a",
   "metadata": {},
   "source": [
    "## LangChain Templates for Domain Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prediction_template = \"\"\"{prediction_properties}\n",
    "\n",
    "{prediction_requirements}\n",
    "\n",
    "{prediction_templates}\n",
    "\n",
    "{prediction_examples}\n",
    "\"\"\"\n",
    "\n",
    "full_prediction_prompt = PromptTemplate.from_template(full_prediction_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec60a77",
   "metadata": {},
   "source": [
    "Google predictive spelling/autocomplete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d420e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_properties_template = \"\"\"A prediction ($p$) = ($p_s$, $p_t$, $p_d$, $p_a$), where it consists of the following four properties:\n",
    "\n",
    "    1. $p_s$, any source entity in the {prediction_domain} domain.\n",
    "        - Can be a person (with a name) or a {prediction_domain} person such as a {prediction_domain} reporter, {prediction_domain} analyst, {prediction_domain} expert, {prediction_domain} top executive, {prediction_domain} senior level person, etc).\n",
    "        - Can only be an organization that is associated with the {prediction_domain} prediction.\n",
    "    2. $p_t$, any target entity in the {prediction_domain} domain.\n",
    "\t      - Can be a person (with a name) or a {prediction_domain} person such as a {prediction_domain} reporter, {prediction_domain} analyst, {prediction_domain} expert, {prediction_domain} top executive, {prediction_domain} senior level person, etc).\n",
    "        - Can only be an organization that is associated with the {prediction_domain} prediction.\n",
    "    3. $p_d$, date range when $p$ is expected to come to fruition.\n",
    "        - Forecast can range from a second to anytime in the future.\n",
    "        - Answers the questions: \"How far to go out from today?\" or \"Where to stop?\".\n",
    "    4. $p_a$, {prediction_domain} prediction attribute.\n",
    "        - Characteristics of a domain-specific attributes such as various quantifiable metrics relevant to the {prediction_domain} domain.\n",
    "        - Some examples are {prediction_domain_attribute}.  \n",
    "\"\"\"\n",
    "prediction_properties_prompt = PromptTemplate.from_template(prediction_properties_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5179fe",
   "metadata": {},
   "source": [
    "    - Keep the brackets around the prediction properties when generating predictions and be sure to include brackets around dates such as \"2024-10-15\", \"2024/08/20\", \"Q4 of 2024\", \"2025\", \"2027 Q1\", \"Q3 2027\", \"On 21 Aug 2024\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95548954",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_requirements_template = \"\"\"{prediction_domain} requirements to use for each prediction:\n",
    "\n",
    "    - Should be based on real-world {prediction_domain} data and not hallucinate.\n",
    "    - Only a simple sentence (prediction) (and NOT compounding using \"and\" or \"or\").\n",
    "    - Should diversify all four properties of the prediction ($p$) as in change and not use same for $p_s$, $p_t$, $p_d$, $p_a$.\n",
    "    - Should use synonyms to predict such as forecasts, speculates, foresee, envision, etc., and not use any of them more than ten times.\n",
    "    - The prediction should be unique and not repeated.\n",
    "    - Do not number the predictions.\n",
    "    - Do not say, \"As the {prediction_domain}, I will generate company-based {prediction_domain} predictions using the provided templates.\" or anything similar.\n",
    "    - Use the five different templates and examples provided.\n",
    "    - Change how the current date ($p_d$) written in the prediction with examples of (1) Wednesday, August 21, 2024; (2) Wed, August 21, 2024; (3) 08/21/2024; (4) 08/21/2024; (5) 21/08/2024; (6) 21 August 2024; (7) 2024/08/21; (8) 2024-08-21; (9) August 21, 2024; (10) Aug 21, 2024; (11) 21 August 2024, (12) 21 Aug 2024, Q3 of 2027, 2029 of Q3, etc (with removing day of week).\n",
    "    {domain_requirements}\n",
    "    - Stop saying, \"Here are {predictions_N} unique {prediction_domain} predictions based on the provided templates and examples:\" in the prompt.\n",
    "    - Do not use any of the examples in the prompt.\n",
    "    - In front of every prodiction, put the template number in the format of \"T1:\", \"T2:\", etc. and do not number them like \"1.\", \"2.\", etc.\n",
    "    - Disregard brackets: \"[]\"\n",
    "    - Should never say \"Here are {predictions_N} unique {prediction_domain} predictions based on the provided templates and examples:\"\n",
    "    - Do not use person name of entity name more than once as in don't use name Joe as both the $p_s$ and $p_t$, unless like Mr. Sach and Goldman Sach or Mr. Sam Walton and Sam's Club, etc.\n",
    "    - Should variate the slope of rise/increase/as much as, fall/decrease/as little as, change, stay stable, high/low chance/probability/degree of, etc.\n",
    "    - Should variate the prediction verbs such as will, would, be going to, should, etc.\n",
    "\"\"\"\n",
    "prediction_requirements_prompt = PromptTemplate.from_template(prediction_requirements_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07129ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_templates_template = \"\"\"Here are some {prediction_domain} templates:\n",
    "\n",
    "- {prediction_domain} template 1: On [ $p_t$ ], [ $p_p$ ] [ $p_w$ ] that the [ $p_a$ ] at [ $p_o$ ] [ $p_v$ ] [ $p_s$ ] by [ $p_m$ ] in [ $p_f$ ].\n",
    "\n",
    "\"\"\"\n",
    "prediction_templates_prompt = PromptTemplate.from_template(prediction_templates_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_examples_template = \"\"\"Here are some examples of {prediction_domain} predictions:\n",
    "\n",
    "{domain_examples}\n",
    "\n",
    "With the above, generate a unique set of {predictions_N} predictions. Think from the perspective of an {prediction_domain} analyst, expert, top executive, or senior level person.\"\"\"\n",
    "prediction_examples_prompt = PromptTemplate.from_template(prediction_examples_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input_prompts = [\n",
    "    (\"prediction_properties\", prediction_properties_prompt),\n",
    "    (\"prediction_requirements\", prediction_requirements_prompt),\n",
    "    (\"prediction_templates\", prediction_templates_prompt),\n",
    "    (\"prediction_examples\", prediction_examples_prompt),\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prediction_prompt, pipeline_prompts=prediction_input_prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b1ddb",
   "metadata": {},
   "source": [
    "## Generate Domain Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd133022",
   "metadata": {},
   "source": [
    "### Generate Financial Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ddf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_attributes = \"\"\"stock price, net profit, revenue, operating cash flow, research and development expenses, operating income, gross profit.\"\"\"\n",
    "financial_requirements = \"\"\"- Should be based on real-world financial earnings reports.\n",
    "    - Suppose the time when $p$ was made is during any earning season.\n",
    "    - Include stocks from all sectors such as consumer staples, energy, finance, health care, industrials, materials, media, real estate, retail, technology, utilities, defense, etc.\n",
    "    - Include the US Dollar sign ($) before or USD after the amount of the financial attribute.\"\"\"\n",
    "\n",
    "financial_examples = \"\"\"\n",
    "- financial examples for template 1:\n",
    "\t\t- {prediction_domain} template 1: [$p_s$] forecasts that the [$p_a$] at [$p_t$] to increase in [$p_d$].\n",
    "\n",
    "    1. [Detravious, an investor] forecasts that the [stock price] at [Apple] will likely decrease in [2025 Q1 to 2025 Q3].\n",
    "    2. [Ava Lee] predicts that the [operating cash flow] at [ExxonMobil] should decrease in [03/21/2025 to 08/21/2025].\n",
    "    \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_input_dict = {\n",
    "    \"prediction_domain\": \"financial\",\n",
    "    \"prediction_domain_attribute\": financial_attributes,\n",
    "    \"domain_requirements\": financial_requirements,\n",
    "    \"domain_examples\": financial_examples,\n",
    "    \"predictions_N\": predictions_N\n",
    "}\n",
    "financial_prompt_output = pipeline_prompt.format(**financial_input_dict)\n",
    "print(financial_prompt_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmf = TextGenerationModelFactory()\n",
    "\n",
    "N_batches = 1\n",
    "# text_generation_models = [llama_instant_generation_model]\n",
    "# text_generation_models = [llama_versatile_generation_model, llama_instant_generation_model, llama_70b_8192_generation_model, llama_8b_8192_generation_model]\n",
    "text_generation_models = [llama_instant_generation_model, llama_8b_8192_generation_model]\n",
    "\n",
    "# text_generation_models = [llama_versatile_generation_model, llama_70b_8192_generation_model, mixtral_generation_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_domains = [\"finance\"]\n",
    "prediction_prompt_outputs = {\n",
    "    \"finance\": financial_prompt_output,\n",
    "}\n",
    "prediction_label = 1\n",
    "\n",
    "batched_predictions_df = tgmf.batch_generate_predictions(N_batches=N_batches, \n",
    "                                text_generation_models=text_generation_models, \n",
    "                                domains=prediction_domains,\n",
    "                                prompt_outputs=prediction_prompt_outputs,\n",
    "                                sentence_label=prediction_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14728864",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaac4c9",
   "metadata": {},
   "source": [
    "### Generate Health Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5834805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "batched_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = DataProcessing.concat_dfs(batched_predictions_df)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a293a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_log_data = predictions_df.to_csv()\n",
    "# csv_log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2025-04-10 14:21:09,464 - INFO - Logging setup complete - logging to: ../data/prediction_logs/test.log\n",
    "\n",
    "# import logging\n",
    "# import os\n",
    "\n",
    "# def setup_logging():\n",
    "#     # Define the directory where you want to save the logs\n",
    "#     log_directory = '../data/prediction_logs/'  # Adjust according to your notebook's path\n",
    "\n",
    "#     # Create the directory if it doesn't exist\n",
    "#     os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "#     # Define the full path to the log file\n",
    "#     log_file_path = os.path.join(log_directory, 'test.log')\n",
    "\n",
    "#     # Clear previous logging configuration\n",
    "#     logging.getLogger().handlers = []\n",
    "\n",
    "#     # Configure the logging module to write to the specified file\n",
    "#     logging.basicConfig(level=logging.INFO,\n",
    "#                         format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#                         handlers=[\n",
    "#                             logging.FileHandler(log_file_path),\n",
    "#                             logging.StreamHandler()\n",
    "#                         ])\n",
    "#     logging.info(\"Logging setup complete - logging to: {}\".format(log_file_path))\n",
    "#     return log_file_path\n",
    "\n",
    "# def log_data():\n",
    "#     # my_list = [1, 2, 3, \"apple\", \"banana\"]\n",
    "#     logging.info(f\"Contents of my_list: {csv_log_data}\")\n",
    "#     print(\"Logging data... check the log file for the output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_file_path = setup_logging()\n",
    "# print(f\"Logging has been set up. Logs will be saved to: {log_file_path}\")\n",
    "# log_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# def read_log_file(log_file_path):\n",
    "#     \"\"\"Opens and reads the content of a log file.\n",
    "\n",
    "#     Args:\n",
    "#         log_file_path (str): The path to the log file.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         with open(log_file_path, 'r') as log_file:\n",
    "#             for line in log_file:\n",
    "#                 print(line.strip())  # Print each line, removing leading/trailing whitespace\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: Log file not found at {log_file_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while reading the log file: {e}\")\n",
    "\n",
    "# log_file = \"../data/prediction_logs/test.log\"\n",
    "# # Now, you can use the read_log_file function to open and read the content\n",
    "# print(\"\\n--- Reading the log file ---\")\n",
    "# read_log_file(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_csv(data_list, csv_file_path):\n",
    "    \"\"\"\n",
    "    Converts a list to a CSV file. Each element of the list becomes a row\n",
    "    with a single column.\n",
    "\n",
    "    Args:\n",
    "        data_list (list): The list to convert.\n",
    "        csv_file_path (str): The path to save the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for item in data_list:\n",
    "                writer.writerow([item])\n",
    "        logging.info(f\"List successfully converted to CSV: {csv_file_path}\")\n",
    "        return csv_file_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting list to CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_csv_to_dataframe(csv_file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file (with a single column) and converts it to a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or None: The DataFrame if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path, header=None, names=['data'])\n",
    "        logging.info(f\"CSV successfully converted to DataFrame.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"CSV file not found: {csv_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting CSV to DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define the output file paths\n",
    "csv_output_path = os.path.join(log_file, 'my_list.csv')\n",
    "\n",
    "# Convert the list to CSV\n",
    "csv_file = convert_list_to_csv(my_list, csv_output_path)\n",
    "\n",
    "if csv_file:\n",
    "    # Convert the CSV to a Pandas DataFrame\n",
    "    df_from_csv = convert_csv_to_dataframe(csv_file)\n",
    "\n",
    "    if df_from_csv is not None:\n",
    "        logging.info(f\"Generated DataFrame:\\n{df_from_csv}\")\n",
    "        print(\"DataFrame created successfully. Check the log file for details.\")\n",
    "    else:\n",
    "        print(\"Failed to create DataFrame. Check the log file for errors.\")\n",
    "else:\n",
    "    print(\"Failed to convert list to CSV. Check the log file for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec896b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = DataFrameLogger()\n",
    "# logger.log_df(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logged_data = logger.load_log()\n",
    "# logged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd14bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store updated_predictions_df\n",
    "# %store updated_non_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a857cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, csv\n",
    "import logging\n",
    "\n",
    "# Configure logging (if not already configured)\n",
    "log_directory = '../data/prediction_logs/'\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "log_file_path = os.path.join(log_directory, 'data_processing.log')\n",
    "\n",
    "if not logging.root.handlers:\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                        filename=log_file_path)\n",
    "    logging.info(f\"Logging configured to save to: {log_file_path}\")\n",
    "else:\n",
    "    logging.info(\"Logging already configured.\")\n",
    "\n",
    "def dataframe_to_csv(df, csv_file_path):\n",
    "    \"\"\"Writes a Pandas DataFrame to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df.to_csv(csv_file_path, index=False)  # index=False to avoid writing DataFrame index\n",
    "        logging.info(f\"DataFrame successfully written to CSV: {csv_file_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing DataFrame to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'col1': [1, 2, 3], 'col2': ['a', 'b', 'c']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "csv_output_path = os.path.join(log_directory, 'from_dataframe.csv')\n",
    "dataframe_to_csv(df, csv_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_log(csv_file_path, log_file_path):\n",
    "    \"\"\"Reads a CSV file and writes its content to a log file.\"\"\"\n",
    "    try:\n",
    "        with open(csv_file_path, 'r') as csvfile, open(log_file_path, 'a') as logfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                log_message = f\"CSV Row: {', '.join(map(str, row))}\"\n",
    "                logfile.write(log_message + '\\n')\n",
    "        logging.info(f\"CSV content successfully written to log file: {log_file_path}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"CSV file not found: {csv_file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error writing CSV to log file: {e}\")\n",
    "        return False\n",
    "\n",
    "csv_input_path = os.path.join(log_directory, 'from_dataframe.csv')\n",
    "log_output_path = os.path.join(log_directory, 'from_csv.log')\n",
    "csv_to_log(csv_input_path, log_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d124d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_csv(log_file_path, csv_file_path, lines_to_ignore=None, delimiter=','):\n",
    "    \"\"\"\n",
    "    Reads a log file, extracts relevant lines, and writes them to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        log_file_path (str): Path to the log file.\n",
    "        csv_file_path (str): Path to save the CSV file.\n",
    "        lines_to_ignore (list, optional): List of strings or patterns to identify lines to skip. Defaults to None.\n",
    "        delimiter (str, optional): Delimiter for the CSV file. Defaults to ','.\n",
    "    \"\"\"\n",
    "    if lines_to_ignore is None:\n",
    "        lines_to_ignore = []\n",
    "\n",
    "    try:\n",
    "        extracted_data = []\n",
    "        with open(log_file_path, 'r') as logfile:\n",
    "            for line in logfile:\n",
    "                skip_line = False\n",
    "                for ignore_pattern in lines_to_ignore:\n",
    "                    if ignore_pattern in line:\n",
    "                        skip_line = True\n",
    "                        break\n",
    "                if not skip_line:\n",
    "                    # Assuming the relevant data in the log file is comma-separated\n",
    "                    # You might need more sophisticated parsing based on your log format\n",
    "                    parts = line.strip().split(delimiter)\n",
    "                    extracted_data.append(parts)\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=delimiter)\n",
    "            writer.writerows(extracted_data)\n",
    "\n",
    "        logging.info(f\"Successfully extracted data from log file to CSV: {csv_file_path}, ignoring lines containing: {lines_to_ignore}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Log file not found: {log_file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing log file to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "log_input_path = os.path.join(log_directory, 'from_csv.log')\n",
    "csv_output_from_log_path = os.path.join(log_directory, 'from_log.csv')\n",
    "ignore_patterns = ['INFO', 'DEBUG', 'ERROR', 'WARNING', 'CSV Row: '] # Example patterns to ignore\n",
    "\n",
    "log_to_csv(log_input_path, csv_output_from_log_path, ignore_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20463eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(csv_file_path):\n",
    "    \"\"\"Reads a CSV file into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        logging.info(f\"CSV file successfully read into DataFrame: {csv_file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"CSV file not found: {csv_file_path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.warning(f\"CSV file is empty: {csv_file_path}\")\n",
    "        return pd.DataFrame() # Return an empty DataFrame\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading CSV file into DataFrame: {e}\")\n",
    "        return None\n",
    "\n",
    "csv_input_from_log_path = os.path.join(log_directory, 'from_dataframe.csv')\n",
    "df_from_log_csv = csv_to_dataframe(csv_input_from_log_path)\n",
    "\n",
    "if df_from_log_csv is not None:\n",
    "    print(\"\\nDataFrame created from log CSV:\")\n",
    "    print(df_from_log_csv)\n",
    "else:\n",
    "    print(\"\\nFailed to create DataFrame from log CSV. Check the log file for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be029e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_log_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad7888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
